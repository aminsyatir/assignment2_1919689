{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aminsyatir/assignment2_1919689/blob/main/Assignment_2_1919689.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "gu5EoMTZpGPe"
      },
      "outputs": [],
      "source": [
        "import torch, torchvision\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import time\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import cv2\n",
        "import glob\n",
        "import numpy\n",
        "import random\n",
        "\n",
        "from PIL import Image\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, models, transforms\n",
        "from torchsummary import summary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PzOVztyLMxWe",
        "outputId": "acfb2716-ed2b-47dc-ed6a-7831630a2c8d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Veui89ripGPp"
      },
      "outputs": [],
      "source": [
        "# Applying Transforms to the Data\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "image_transforms = {\n",
        "    'train': transforms.Compose([\n",
        "        transforms.RandomResizedCrop(size=256, scale=(0.8, 1.0)),\n",
        "        transforms.RandomRotation(degrees=15),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.CenterCrop(size=224),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406],\n",
        "                             [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "    'test': transforms.Compose([\n",
        "        transforms.Resize(size=256),\n",
        "        transforms.CenterCrop(size=224),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406],\n",
        "                             [0.229, 0.224, 0.225])\n",
        "    ])\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "sGWbs8c-pGPr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "30b37d4d-8aa9-4c04-84fb-825af771b489"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n",
            "4\n"
          ]
        }
      ],
      "source": [
        "# Load the Data\n",
        "\n",
        "# Set train and valid directory paths\n",
        "\n",
        "#dataset = '/content/drive/My Drive/01. TEACHING/MACHINE_VISION/code/fruit_dataset'\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "dataset = '/content/gdrive/My Drive/fruit_dataset'\n",
        "\n",
        "train_directory = os.path.join(dataset, 'train') \n",
        "test_directory = os.path.join(dataset, 'validation')\n",
        "\n",
        "# Batch size\n",
        "batchSize = 64\n",
        "\n",
        "# Number of classes\n",
        "num_classes = len(os.listdir(train_directory))\n",
        "print(num_classes)\n",
        "\n",
        "# Load Data from folders\n",
        "data = {\n",
        "    'train': datasets.ImageFolder(root=train_directory, transform=image_transforms['train']),\n",
        "\n",
        "    'test': datasets.ImageFolder(root=test_directory, transform=image_transforms['test'])\n",
        "}\n",
        "\n",
        "# Get a mapping of the indices to the class names, in order to see the output classes of the test images.\n",
        "# idx_to_class = {v: k for k, v in data['train'].class_to_idx.items()}\n",
        "# print(idx_to_class)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L4m0JrIXpGPt",
        "outputId": "c8b933d6-ad3c-4936-f294-63f4542233d0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset ImageFolder\n",
              "    Number of datapoints: 482\n",
              "    Root location: /content/gdrive/My Drive/fruit_dataset/train\n",
              "    StandardTransform\n",
              "Transform: Compose(\n",
              "               RandomResizedCrop(size=(256, 256), scale=(0.8, 1.0), ratio=(0.75, 1.3333), interpolation=bilinear)\n",
              "               RandomRotation(degrees=[-15.0, 15.0], interpolation=nearest, expand=False, fill=0)\n",
              "               RandomHorizontalFlip(p=0.5)\n",
              "               CenterCrop(size=(224, 224))\n",
              "               ToTensor()\n",
              "               Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
              "           )"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "data['train']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "JuZoH8SVpGPu"
      },
      "outputs": [],
      "source": [
        "# Size of Data, to be used for calculating Average Loss and Accuracy\n",
        "train_data_size = len(data['train'])\n",
        "# valid_data_size = len(data['valid'])\n",
        "test_data_size = len(data['test'])\n",
        "\n",
        "# Create iterators for the Data loaded using DataLoader module\n",
        "train_data_loader = DataLoader(data['train'], batch_size=batchSize, shuffle=True)\n",
        "# valid_data_loader = DataLoader(data['valid'], batch_size=batchSize, shuffle=True)\n",
        "test_data_loader = DataLoader(data['test'], batch_size=batchSize, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lllGMRytpGPv",
        "outputId": "224be1c3-ef14-4380-aa40-c4c30498e06e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(482, 371)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "train_data_size, test_data_size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "7pHq9YTbpGPw"
      },
      "outputs": [],
      "source": [
        "input_size = (3,32,32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jTuCiNMepGPx",
        "outputId": "7da21882-f1a2-4bb9-cae0-59a88fcf7d48"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "482\n",
            "371\n"
          ]
        }
      ],
      "source": [
        "#######################################################\n",
        "#                  Create Dataloader                     #\n",
        "#######################################################\n",
        "\n",
        "# Turn train and test custom Dataset's into DataLoader's\n",
        "from torch.utils.data import DataLoader\n",
        "trainloader = DataLoader(dataset=data['train'], # use custom created train Dataset\n",
        "                                     batch_size=16, # how many samples per batch?\n",
        "                                     num_workers=0, # how many subprocesses to use for data loading? (higher = more)\n",
        "                                     shuffle=True) # shuffle the data?\n",
        "\n",
        "testloader = DataLoader(dataset=data['test'], # use custom created test Dataset\n",
        "                                    batch_size=16, \n",
        "                                    num_workers=0, \n",
        "                                    shuffle=False) # don't usually need to shuffle testing data\n",
        "\n",
        "train_data_size = len(trainloader.dataset)\n",
        "test_data_size = len(testloader.dataset)\n",
        "\n",
        "print(train_data_size)\n",
        "print(test_data_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "24467040af7844ce80d75b6f3bfff95a",
            "5abe6efdfef54ce38e3be7935ecb70d8",
            "abab27aceb004801a37f2fe90620c380",
            "895143685ea34162acaee75e5cc58d7f",
            "d5a7f46aedf5448fa8b03c205bd4786d",
            "f6c8b86d7ceb4fd8a497570528bd01cd",
            "4867f348618f48a08f2ff5bdf9884c4c",
            "ac0eb3da0e84414bb2901044f22eea4d",
            "5ff148ca407e43a9b3d509eba45b4009",
            "9bea6abd53c04a3cac498da0b390c872",
            "8e541fff26824886a033eb49fc4eea40"
          ]
        },
        "id": "z7TYXzQ4pGPy",
        "outputId": "043305bd-fa37-4e9c-b190-ade4fbfb3f23"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchvision/models/_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n",
            "  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and will be removed in 0.15, \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0.00/97.8M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "24467040af7844ce80d75b6f3bfff95a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ResNet(\n",
              "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (relu): ReLU(inplace=True)\n",
              "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "  (layer1): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (layer2): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (3): Bottleneck(\n",
              "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (layer3): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (3): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (4): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (5): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (layer4): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              "  (fc): Linear(in_features=2048, out_features=1000, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "#######################\n",
        "model = models.resnet50(pretrained = True)\n",
        "#######################\n",
        "\n",
        "\n",
        "# 2. LOSS AND OPTIMIZER\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
        "\n",
        "# 3. move the model to GPU\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "bEVE8du9pGPz"
      },
      "outputs": [],
      "source": [
        "import time # to calculate training time\n",
        "\n",
        "def train_and_validate(model, loss_criterion, optimizer, epochs=25):\n",
        "    '''\n",
        "    Function to train and validate\n",
        "    Parameters\n",
        "        :param model: Model to train and validate\n",
        "        :param loss_criterion: Loss Criterion to minimize\n",
        "        :param optimizer: Optimizer for computing gradients\n",
        "        :param epochs: Number of epochs (default=25)\n",
        "  \n",
        "    Returns\n",
        "        model: Trained Model with best validation accuracy\n",
        "        history: (dict object): Having training loss, accuracy and validation loss, accuracy\n",
        "    '''\n",
        "    \n",
        "    start = time.time()\n",
        "    history = []\n",
        "    best_acc = 0.0\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        epoch_start = time.time()\n",
        "        print(\"Epoch: {}/{}\".format(epoch+1, epochs))\n",
        "        \n",
        "        # Set to training mode\n",
        "        model.train()\n",
        "        \n",
        "        # Loss and Accuracy within the epoch\n",
        "        train_loss = 0.0\n",
        "        train_acc = 0.0\n",
        "        \n",
        "        valid_loss = 0.0\n",
        "        valid_acc = 0.0\n",
        "        \n",
        "        for i, (inputs, labels) in enumerate(trainloader):\n",
        "\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "            \n",
        "            # Clean existing gradients\n",
        "            optimizer.zero_grad()\n",
        "            \n",
        "            # Forward pass - compute outputs on input data using the model\n",
        "            outputs = model(inputs)\n",
        "            \n",
        "            # Compute loss\n",
        "            loss = loss_criterion(outputs, labels)\n",
        "            \n",
        "            # Backpropagate the gradients\n",
        "            loss.backward()\n",
        "            \n",
        "            # Update the parameters\n",
        "            optimizer.step()\n",
        "            \n",
        "            # Compute the total loss for the batch and add it to train_loss\n",
        "            train_loss += loss.item() * inputs.size(0)\n",
        "            \n",
        "            # Compute the accuracy\n",
        "            ret, predictions = torch.max(outputs.data, 1)\n",
        "            correct_counts = predictions.eq(labels.data.view_as(predictions))\n",
        "            \n",
        "            # Convert correct_counts to float and then compute the mean\n",
        "            acc = torch.mean(correct_counts.type(torch.FloatTensor))\n",
        "            \n",
        "            # Compute total accuracy in the whole batch and add to train_acc\n",
        "            train_acc += acc.item() * inputs.size(0)\n",
        "            \n",
        "            #print(\"Batch number: {:03d}, Training: Loss: {:.4f}, Accuracy: {:.4f}\".format(i, loss.item(), acc.item()))\n",
        "\n",
        "            \n",
        "        # Validation - No gradient tracking needed\n",
        "        with torch.no_grad():\n",
        "\n",
        "            # Set to evaluation mode\n",
        "            model.eval()\n",
        "\n",
        "            # Validation loop\n",
        "            for j, (inputs, labels) in enumerate(testloader):\n",
        "                inputs = inputs.to(device)\n",
        "                labels = labels.to(device)\n",
        "\n",
        "                # Forward pass - compute outputs on input data using the model\n",
        "                outputs = model(inputs)\n",
        "\n",
        "                # Compute loss\n",
        "                loss = loss_criterion(outputs, labels)\n",
        "\n",
        "                # Compute the total loss for the batch and add it to valid_loss\n",
        "                valid_loss += loss.item() * inputs.size(0)\n",
        "\n",
        "                # Calculate validation accuracy\n",
        "                ret, predictions = torch.max(outputs.data, 1)\n",
        "                correct_counts = predictions.eq(labels.data.view_as(predictions))\n",
        "\n",
        "                # Convert correct_counts to float and then compute the mean\n",
        "                acc = torch.mean(correct_counts.type(torch.FloatTensor))\n",
        "\n",
        "                # Compute total accuracy in the whole batch and add to valid_acc\n",
        "                valid_acc += acc.item() * inputs.size(0)\n",
        "\n",
        "                #print(\"Validation Batch number: {:03d}, Validation: Loss: {:.4f}, Accuracy: {:.4f}\".format(j, loss.item(), acc.item()))\n",
        "            \n",
        "        # Find average training loss and training accuracy\n",
        "        avg_train_loss = train_loss/train_data_size \n",
        "        avg_train_acc = train_acc/train_data_size\n",
        "\n",
        "        # Find average training loss and training accuracy\n",
        "        avg_test_loss = valid_loss/test_data_size \n",
        "        avg_test_acc = valid_acc/test_data_size\n",
        "\n",
        "        history.append([avg_train_loss, avg_test_loss, avg_train_acc, avg_test_acc])\n",
        "                \n",
        "        epoch_end = time.time()\n",
        "    \n",
        "        print(\"Epoch : {:03d}, Training: Loss: {:.4f}, Accuracy: {:.4f}%, \\n\\t\\tValidation : Loss : {:.4f}, Accuracy: {:.4f}%, Time: {:.4f}s\".format(epoch, avg_train_loss, avg_train_acc*100, avg_test_loss, avg_test_acc*100, epoch_end-epoch_start))\n",
        "        \n",
        "        # Save if the model has best accuracy till now\n",
        "        torch.save(model, 'cifar10_model_'+str(epoch)+'.pt')\n",
        "            \n",
        "    return model, history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k9tt7xW0pGP0",
        "outputId": "edc4fefd-ac46-4888-88a5-102096025abd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1/25\n",
            "Epoch : 000, Training: Loss: 2.5261, Accuracy: 62.0332%, \n",
            "\t\tValidation : Loss : 1.1708, Accuracy: 73.0458%, Time: 132.3745s\n",
            "Epoch: 2/25\n",
            "Epoch : 001, Training: Loss: 0.1667, Accuracy: 94.3983%, \n",
            "\t\tValidation : Loss : 0.4113, Accuracy: 90.0270%, Time: 9.7394s\n",
            "Epoch: 3/25\n",
            "Epoch : 002, Training: Loss: 0.0883, Accuracy: 97.3029%, \n",
            "\t\tValidation : Loss : 0.5458, Accuracy: 88.1402%, Time: 9.6304s\n",
            "Epoch: 4/25\n",
            "Epoch : 003, Training: Loss: 0.0608, Accuracy: 98.3402%, \n",
            "\t\tValidation : Loss : 0.3800, Accuracy: 90.0270%, Time: 9.6472s\n",
            "Epoch: 5/25\n",
            "Epoch : 004, Training: Loss: 0.0504, Accuracy: 98.3402%, \n",
            "\t\tValidation : Loss : 0.3068, Accuracy: 91.9137%, Time: 9.6839s\n",
            "Epoch: 6/25\n",
            "Epoch : 005, Training: Loss: 0.0527, Accuracy: 98.5477%, \n",
            "\t\tValidation : Loss : 0.1987, Accuracy: 94.6092%, Time: 9.8096s\n",
            "Epoch: 7/25\n",
            "Epoch : 006, Training: Loss: 0.0216, Accuracy: 99.3776%, \n",
            "\t\tValidation : Loss : 0.2922, Accuracy: 93.5310%, Time: 9.9144s\n",
            "Epoch: 8/25\n",
            "Epoch : 007, Training: Loss: 0.0411, Accuracy: 99.3776%, \n",
            "\t\tValidation : Loss : 0.2933, Accuracy: 93.5310%, Time: 9.9186s\n",
            "Epoch: 9/25\n",
            "Epoch : 008, Training: Loss: 0.0628, Accuracy: 98.5477%, \n",
            "\t\tValidation : Loss : 0.4819, Accuracy: 87.0620%, Time: 9.8040s\n",
            "Epoch: 10/25\n",
            "Epoch : 009, Training: Loss: 0.0436, Accuracy: 98.7552%, \n",
            "\t\tValidation : Loss : 0.4111, Accuracy: 90.8356%, Time: 9.7791s\n",
            "Epoch: 11/25\n",
            "Epoch : 010, Training: Loss: 0.0577, Accuracy: 98.1328%, \n",
            "\t\tValidation : Loss : 0.4720, Accuracy: 89.4879%, Time: 9.7939s\n",
            "Epoch: 12/25\n",
            "Epoch : 011, Training: Loss: 0.0865, Accuracy: 97.3029%, \n",
            "\t\tValidation : Loss : 0.4381, Accuracy: 88.9488%, Time: 9.7560s\n",
            "Epoch: 13/25\n",
            "Epoch : 012, Training: Loss: 0.0785, Accuracy: 96.6805%, \n",
            "\t\tValidation : Loss : 0.3702, Accuracy: 91.1051%, Time: 9.7977s\n",
            "Epoch: 14/25\n",
            "Epoch : 013, Training: Loss: 0.0147, Accuracy: 99.5851%, \n",
            "\t\tValidation : Loss : 0.3515, Accuracy: 91.1051%, Time: 9.8447s\n",
            "Epoch: 15/25\n",
            "Epoch : 014, Training: Loss: 0.0180, Accuracy: 99.3776%, \n",
            "\t\tValidation : Loss : 0.3953, Accuracy: 90.5660%, Time: 9.8294s\n",
            "Epoch: 16/25\n",
            "Epoch : 015, Training: Loss: 0.0544, Accuracy: 98.9627%, \n",
            "\t\tValidation : Loss : 0.3443, Accuracy: 92.4528%, Time: 9.8150s\n",
            "Epoch: 17/25\n",
            "Epoch : 016, Training: Loss: 0.0385, Accuracy: 99.7925%, \n",
            "\t\tValidation : Loss : 0.3181, Accuracy: 92.9919%, Time: 9.8762s\n",
            "Epoch: 18/25\n",
            "Epoch : 017, Training: Loss: 0.0575, Accuracy: 98.7552%, \n",
            "\t\tValidation : Loss : 0.4091, Accuracy: 90.2965%, Time: 9.8368s\n",
            "Epoch: 19/25\n",
            "Epoch : 018, Training: Loss: 0.0985, Accuracy: 96.8880%, \n",
            "\t\tValidation : Loss : 0.4857, Accuracy: 91.9137%, Time: 9.8347s\n",
            "Epoch: 20/25\n",
            "Epoch : 019, Training: Loss: 0.0674, Accuracy: 97.9253%, \n",
            "\t\tValidation : Loss : 0.4129, Accuracy: 91.3747%, Time: 9.8318s\n",
            "Epoch: 21/25\n",
            "Epoch : 020, Training: Loss: 0.0481, Accuracy: 97.9253%, \n",
            "\t\tValidation : Loss : 0.2950, Accuracy: 92.9919%, Time: 9.7898s\n",
            "Epoch: 22/25\n",
            "Epoch : 021, Training: Loss: 0.0795, Accuracy: 97.0954%, \n",
            "\t\tValidation : Loss : 0.4611, Accuracy: 91.9137%, Time: 9.7797s\n",
            "Epoch: 23/25\n",
            "Epoch : 022, Training: Loss: 0.0375, Accuracy: 98.3402%, \n",
            "\t\tValidation : Loss : 0.1026, Accuracy: 95.9569%, Time: 9.8099s\n",
            "Epoch: 24/25\n",
            "Epoch : 023, Training: Loss: 0.0574, Accuracy: 98.1328%, \n",
            "\t\tValidation : Loss : 0.1641, Accuracy: 95.9569%, Time: 9.8374s\n",
            "Epoch: 25/25\n",
            "Epoch : 024, Training: Loss: 0.0465, Accuracy: 98.3402%, \n",
            "\t\tValidation : Loss : 0.1393, Accuracy: 96.4960%, Time: 9.7790s\n"
          ]
        }
      ],
      "source": [
        "# 4. Train the model for 25 epochs\n",
        " \n",
        "num_epochs = 25\n",
        "trained_model, history = train_and_validate(model, criterion, optimizer, num_epochs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "T3ceVl6PMWET",
        "outputId": "1de6be96-8585-41e9-e5ac-2c41667ba3fc"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYYAAAEKCAYAAAAW8vJGAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deXzcVb3/8dcn+7616b7TQmlLaaGlxcouCoIWAZWKYEFFuQgiesWrV0F+cEVF1AqCVeECIgWVVZbKZUe2LnSlpZQuNN2TNPs+c35/nEkySZM0TTKZJPN+Ph7zmO2b75zJJN/3nHO+38/XnHOIiIg0iot2A0REpG9RMIiISAsKBhERaUHBICIiLSgYRESkBQWDiIi0ELFgMLMUM3vHzFab2Xoz+2kbyySb2cNmttnM3jazcZFqj4iIdE4kewy1wOnOuWOBGcBZZja31TJfBQ445yYCvwZ+HsH2iIhIJ0QsGJxXEbqbGLq0PppuPnBf6PbfgTPMzCLVJhERObSESK7czOKBFcBE4E7n3NutFhkJ7ABwzjWYWSkwCChstZ4rgCsA0tPTj588eXIkmy0iMuCsWLGi0DmX35llIxoMzrkAMMPMcoDHzGyac25dF9azGFgMMGvWLLd8+fIebqmIyMBmZts7u2yv7JXknCsBXgLOavXUTmA0gJklANlAUW+0SURE2hbJvZLyQz0FzCwVOBPY2GqxJ4GvhG5fCLzoVNVPRCSqIjmUNBy4LzTPEAc84pz7p5ndBCx3zj0J/Bl4wMw2A8XARRFsj4iIdELEgsE5twaY2cbjPwm7XQN8PlJtEJGBob6+noKCAmpqaqLdlD4vJSWFUaNGkZiY2OV1RHTyWUSkJxQUFJCZmcm4cePQHu3tc85RVFREQUEB48eP7/J6VBJDRPq8mpoaBg0apFA4BDNj0KBB3e5ZKRhEpF9QKHROT/yeFAwiItKCgkFE5BCKioqYMWMGM2bMYNiwYYwcObLpfl1d3UHLv/zyy5x77rlRaGnP0OSziMghDBo0iFWrVgFw4403kpGRwfe+972m5xsaGkhIGDibU/UYRES6YOHChXzzm99kzpw5fP/73+/Uzzz00EMcc8wxTJs2jeuvvx6AQCDAwoULmTZtGscccwy//vWvAVi0aBFTpkxh+vTpXHRR7x7iNXAiTkRiwk+fWs97u8p6dJ1TRmRxw2emHvbPFRQU8MYbbxAfH3/IZXft2sX111/PihUryM3N5ZOf/CSPP/44o0ePZufOnaxb58vIlZSUAHDrrbeydetWkpOTmx7rLeoxiIh00ec///lOhQLAsmXLOPXUU8nPzychIYGLL76YV199lQkTJrBlyxauvvpqnnvuObKysgCYPn06F198MX/5y196fZhKPQYR6Ve68s0+UtLT07u9jtzcXFavXs3SpUu5++67eeSRR7jnnnt4+umnefXVV3nqqae45ZZbWLt2ba8FhHoMIiK94IQTTuCVV16hsLCQQCDAQw89xCmnnEJhYSHBYJALLriAm2++mZUrVxIMBtmxYwennXYaP//5zyktLaWiouLQL9JD1GMQEYmAF154gVGjRjXd/9vf/satt97KaaedhnOOc845h/nz57N69Wouu+wygsEgAD/72c8IBAJ8+ctfprS0FOcc11xzDTk5Ob3WdutvVa51oh6R2LNhwwaOPvroaDej32jr92VmK5xzszrz8xpKEhGRFhQMIiLSgoJBRERaUDCIiEgLCgYREWlBwSAiIi0oGEREDuG0005j6dKlLR77zW9+w5VXXtnuz5x66qm0tWt9e4/3JQoGEZFDWLBgAUuWLGnx2JIlS1iwYEGUWhRZCgYRkUO48MILefrpp5tOyrNt2zZ27drFSSedxJVXXsmsWbOYOnUqN9xwQ5fWX1xczHnnncf06dOZO3cua9asAeCVV15pOiHQzJkzKS8vZ/fu3Zx88snMmDGDadOm8dprr/XY+2ykkhgi0r88+wPYs7Zn1znsGDj71nafzsvL44QTTuDZZ59l/vz5LFmyhC984QuYGbfccgt5eXkEAgHOOOMM1qxZw/Tp0w/r5W+44QZmzpzJ448/zosvvsill17KqlWruO2227jzzjuZN28eFRUVpKSksHjxYj71qU/xox/9iEAgQFVVVXff/UHUYxAR6YTw4aTwYaRHHnmE4447jpkzZ7J+/Xree++9w17366+/ziWXXALA6aefTlFREWVlZcybN4/rrruORYsWUVJSQkJCArNnz+bee+/lxhtvZO3atWRmZvbcmwxRj0FE+pcOvtlH0vz58/nOd77DypUrqaqq4vjjj2fr1q3cdtttLFu2jNzcXBYuXEhNTU2PveYPfvADzjnnHJ555hnmzZvH0qVLOfnkk3n11Vd5+umnWbhwIddddx2XXnppj70mqMcgItIpGRkZnHbaaVx++eVNvYWysjLS09PJzs5m7969PPvss11a90knncSDDz4IwMsvv8zgwYPJysriww8/5JhjjuH6669n9uzZbNy4ke3btzN06FC+/vWv87WvfY2VK1f22HtspB6DiEgnLViwgM997nNNQ0rHHnssM2fOZPLkyYwePZp58+Z1aj3nnHMOiYmJAJx44on84Q9/4PLLL2f69OmkpaVx3333AX6X2Jdeeom4uDimTp3K2WefzZIlS/jlL39JYmIiGRkZ3H///T3+PiNWdtvMRgP3A0MBByx2zv221TKnAk8AW0MPPeqcu6mj9Xa17LZzjsq6AKmJ8cTH2WH/vIhEj8puH56+XHa7Afiuc24KMBe4ysymtLHca865GaFLh6HQHU+u3sW0G5ayragyUi8hIjIgRCwYnHO7nXMrQ7fLgQ3AyEi93qFkp/puW0lVXbSaICLSL/TK5LOZjQNmAm+38fSJZrbazJ41s4id5Ts3LQmAA5X1kXoJEYmg/na2yWjpid9TxIPBzDKAfwDXOufKWj29EhjrnDsW+B3weDvruMLMlpvZ8v3793epHU3BoB6DSL+TkpJCUVGRwuEQnHMUFRWRkpLSrfVEdK8kM0vEh8KDzrlHWz8fHhTOuWfM7PdmNtg5V9hqucXAYvCTz11pS05641CSegwi/c2oUaMoKCigq18MY0lKSgqjRo3q1joiFgxmZsCfgQ3OudvbWWYYsNc558zsBHwPpigS7clMTiAhztRjEOmHEhMTGT9+fLSbETMi2WOYB1wCrDWzVaHHfgiMAXDO3Q1cCFxpZg1ANXCRi1Bf0czISUvkgHoMIiIdilgwOOdeBzo8YMA5dwdwR6Ta0FpOWpL2ShIROYSYKomRm5aooSQRkUOIqWDwPQYNJYmIdCSmgkE9BhGRQ4uxYEjiQFW99oUWEelATAVDTloSdQ1BqusD0W6KiEifFVPBkJvmD3LTLqsiIu2LqWDIaaqXpHkGEZH2xFQwNPYYtGeSiEj7YisY0lVIT0TkUGIqGHLSdE4GEZFDia1gSG3sMWgoSUSkPTEVDEkJcWQkJ2goSUSkAzEVDOCHkzT5LCLSvpgLBn/0s3oMIiLtiblg0DkZREQ6FnPBkKtzMoiIdCgGgyFRRz6LiHQg5oIhJy2JspoGGgLBaDdFRKRPirlgaCyLUVqteQYRkbbEXjCk6yA3EZGOxFwwNFZY1QS0iEjbYi4YdE4GEZGOxWAwqMKqiEhHYi4YVGFVRKRjMRcMGckJJMSZhpJERNoRc8FgZuTo6GcRkXbFXDBA49HP6jGIiLQlRoNBFVZFRNoTsWAws9Fm9pKZvWdm683s220sY2a2yMw2m9kaMzsuUu0Jp3MyiIi0L5I9hgbgu865KcBc4Cozm9JqmbOBSaHLFcBdEWxPE/UYRETaF7FgcM7tds6tDN0uBzYAI1stNh+433lvATlmNjxSbWqUk+57DM65SL+UiEi/0ytzDGY2DpgJvN3qqZHAjrD7BRwcHpjZFWa23MyW79+/v9vtyU1Loi4QpKou0O11iYgMNBEPBjPLAP4BXOucK+vKOpxzi51zs5xzs/Lz87vdpuayGBpOEhFpLaLBYGaJ+FB40Dn3aBuL7ARGh90fFXosopoL6WkCWkSktUjulWTAn4ENzrnb21nsSeDS0N5Jc4FS59zuSLWpkeoliYi0LyGC654HXAKsNbNVocd+CIwBcM7dDTwDfBrYDFQBl0WwPU1UYVVEpH0RCwbn3OuAHWIZB1wVqTa0R+dkEBFpX0we+dxYYVVlMUREDhaTwZAYH0dmcoLmGERE2hCTwQCNB7kpGEREWovZYPBlMTSUJCLSWswGg87JICLStpgNhty0RPUYRETaEMPBoAqrIiJtidlgyE5NpLymgYZAMNpNERHpU2I2GBqPfi6p1nCSiEi42A2GdB39LCLSlpgNhpymQnrqMYiIhIvZYGgqpFepHoOISLgYDgadk0FEpC0xGww5OoubiEibYjYYMpITSIgzzTGIiLQSs8FgZiqLISLShpgNBmgsi6FgEBEJF+PBoAqrIiKtxXQw5KTpnAwiIq3FdDCoxyAicrCYDobGs7g556LdFBGRPiOmgyE3LYn6gKOyLhDtpoiI9BmdCgYzSzezuNDtI83ss2aWGNmmRZ7KYoiIHKyzPYZXgRQzGwn8C7gE+N9INaq35KgshojIQTobDOacqwLOB37vnPs8MDVyzeoduU0VVtVjEBFp1OlgMLMTgYuBp0OPxUemSb0nV/WSREQO0tlguBb4L+Ax59x6M5sAvBS5ZvWOxqGkUp3FTUSkSaeCwTn3inPus865n4cmoQudc9d09DNmdo+Z7TOzde08f6qZlZrZqtDlJ11of7c0VVitVDCIiDTq7F5JfzWzLDNLB9YB75nZfx7ix/4XOOsQy7zmnJsRutzUmbb0pMT4ODKTEzSUJCISprNDSVOcc2XAecCzwHj8nkntcs69ChR3r3mR13iQm4iIeJ0NhsTQcQvnAU865+qBnjhc+EQzW21mz5pZu3s5mdkVZrbczJbv37+/B162mcpiiIi01Nlg+AOwDUgHXjWzsUBZN197JTDWOXcs8Dvg8fYWdM4tds7Ncs7Nys/P7+bLtqRzMoiItNTZyedFzrmRzrlPO287cFp3Xtg5V+acqwjdfgbfKxncnXV2hT8ng3oMIiKNOjv5nG1mtzcO55jZr/C9hy4zs2FmZqHbJ4TaUtSddXaFH0pSj0FEpFFCJ5e7B7830hdC9y8B7sUfCd0mM3sIOBUYbGYFwA1AIoBz7m7gQuBKM2sAqoGLXBTKnOakJVJe00BDIEhCfEzXFBQRATofDEc45y4Iu/9TM1vV0Q845xYc4vk7gDs6+foR01gWo6S6nsEZyVFujYhI9HX2K3K1mX288Y6ZzcN/y+/3Gg9y0wS0iIjX2R7DN4H7zSw7dP8A8JXINKl3NRfS0wS0iAh0Mhicc6uBY80sK3S/zMyuBdZEsnG9oSkYdE4GERHgMM/gFtrFtPH4hesi0J5e1zyUpB6DiAh079Se1mOtiKLcdJ2TQUQkXHeCodd3LY2E9KR4EuNNcwwiIiEdzjGYWTltB4ABqRFpUS8zM5XFEBEJ02EwOOcye6sh0eTLYigYRESge0NJA0aOKqyKiDRRMOB7DBpKEhHxFAzonAwiIuEUDDSfkyEKNfxERPocBQN+KKk+4KisC0S7KSIiUadgQGUxRETCKRhQWQwRkXAKBlQWQ0QknIIBP8cACgYREYilYPjgeVh0HFTsO+ipnMazuGkoSUQkhoIhOQuKP4Qdbx/0VE6qegwiIo1iJxhGzID4ZPjorYOeSoiPIzMlQT0GERFiKRgSkmHEzDZ7DNB49LN6DCIisRMMAGPmwK5VUF990FO+wqp6DCIisRUMo+dCsB52vXvQUzong4iIF2PBMMdftzHPoHMyiIh4sRUM6YNg0KS290xKS6KkUkNJIiKxFQzg5xl2vA3BYIuHc9OSKK9toD4QbOcHRURiQ+wFw+i5UH0Aij5o8XBuuuoliYhABIPBzO4xs31mtq6d583MFpnZZjNbY2bHRaotLYyZ669bzTM0H/2seQYRiW2R7DH8L3BWB8+fDUwKXa4A7opgW5oNmghpgw6aZ2iul6Qeg4jEtogFg3PuVaC4g0XmA/c77y0gx8yGR6o9Tcz83kmtegxN52RQj0FEYlw05xhGAjvC7heEHjuImV1hZsvNbPn+/fu7/8qj5/i6SRXN62o+J4OCQURiW7+YfHbOLXbOzXLOzcrPz+/+ChvnGcKGk5p7DBpKEpHYFs1g2AmMDrs/KvRY5A2fAfFJsKN5OCktKZ6k+DgNJYlIzItmMDwJXBraO2kuUOqc290rr5yY4gvqfdTcYzAzctISdZCbiMS8hEit2MweAk4FBptZAXADkAjgnLsbeAb4NLAZqAIui1Rb2jR6Drx9N9TX+KBAFVZFRCCCweCcW3CI5x1wVaRe/5DGzIU3FvmCemNPBPwEtA5wE5FY1y8mnyOisaBe2DyDegwiIrEcDOmD/cFuYfMMuek6J4OISOwGA/i6STveBueA5nMyuNB9EZFYFNvBMGYOVBdDoS+ol5uWSEPQUVHbEOWGiYhET2wHw+jGA938PENzIT0NJ4lI7IrtYBg8CVLzmuYZVC9JRCTWg6GxoF6ox6AKqyIisR4M4OcZijZDZaHOySAigoIhbJ7h7eYeQ6WCQURil4JhxExfUO+jt8hO1VCSiIiCITHFV1vd8TYJ8XFkpiRoKElEYpqCAfw8w653ob4mVBZDPQYRiV0KBvDzDIE62L2K3LRE7a4qIjFNwQDNBfU+eitUFkM9BhGJXQoGgIx8yDuiac8k9RhEJJYpGBqN8QX1clJ1TgYRiW0Khkaj50BVEeNtNxW1DdQ1BKPdIhGRqFAwNBrjD3SbVLsOgJJqDSeJSGxSMDQaNAlScxlZsQZQhVURiV0KhkZxcTB6DvkHVgEqiyEisUvBEG70HNLKtpBLmQ5yE5GYpWAIF5pnOD7uA5XFEJGYpWAIN2ImLi6RWXGb1GMQkZilYAiXmAojZjA7bpN6DCISsxQMrdjoOUyL20JZRUW0myIiEhUKhtbGzCWZerJL3ot2S0REokLB0FqooN7I8tWH/7PBIKz6K+zf1MONEhHpPRENBjM7y8zeN7PNZvaDNp5faGb7zWxV6PK1SLanUzKGsC9hBBOq1x3ez1UWwYMXwuNXwp8/AQXLI9M+EZEIi1gwmFk8cCdwNjAFWGBmU9pY9GHn3IzQ5U+Ras/hKMicztENG8C5Tv7ACvjDybDtNTjjBkjNhfvnw9bXIttQEZEIiGSP4QRgs3Nui3OuDlgCzI/g6/WYfTkzyKMMV/Rhxws6B+/8Ee75FFgcXL4UTroOLnsOskf5HsSmf/VOo0VEekgkg2EksCPsfkHosdYuMLM1ZvZ3MxsdwfZ0Wnn+8QDUbHmj/YVqK+AfX4NnvgdHnAbfeAVGHuefyxoOC5+B/KNgyQJY/1gvtFqkn6kqhmAg2q2QNkR78vkpYJxzbjrwPHBfWwuZ2RVmttzMlu/fvz/ijXL5R1Hq0ghse7PtBfa/D388HdY/Cqf/GBY8DGl5LZdJHwRfeQpGzYa/Xw7v/iXi7e536qrgoS/Bkoth8//5yftIaKiDsl2dHxqUyHEOPnwRHvw8/GI8/HYGvHY7VBZGu2USJiGC694JhPcARoUea+KcKwq7+yfgF22tyDm3GFgMMGvWrIj/d+emp7AieCQf2/XOwU+u/Ts8eY0/GO6Sx2DCqe2vKCUbvvwPePjL8MRVUFcJc74RqWb3Lw118MglfiORmgsb/wk5Y+H4hTDzy5AxpHvrDwZg2+uw7u/w3pNQUwIpOTB8Ogw/FoYd668HHQFx8T3ylqQD9dWw5mF4627YvwHS8+Fj18Cud+GFn8LLP4Op58Psr8GoWWAWvbZ+9BYMnQbJGdFrQ5RFMhiWAZPMbDw+EC4CvhS+gJkNd87tDt39LLAhgu3ptNy0RF4MHsnpJY/47m5aHjTUwtIfwbI/wui58Pl7IWvEoVeWlA4Llvhew7Pfh9pyOOm70f3Dj7ZgAB77hu8lfPZ3MP2LPhiW3+s3Ei/9Dxx9Lhx/GYw/ufO/K+dg5wof3usfg4o9kJgOk8+Bkcf7DdLuNfD2YgjU+p9JTIdh02BYKDCGT4f8oyEhKXLvP5aU7YZlf4Ll90B1MQw7Bs67C6ZdAAnJfpl9G/0yq5fAmiX+c5j9db9MUlrvtdU5ePWX8NItMP0iOP8PvffafYy5CHavzezTwG+AeOAe59wtZnYTsNw596SZ/QwfCA1AMXClc25jR+ucNWuWW748sruCbt5XwY9+fTcPJ/8/P0w0dCr87St+o3Pit+ATN0J84uGtNNAAT/yH/9Y071q/jlgMB+fg6ev8huLMm2Det1s+X/gBrPhfWPUgVB+AQRN9L+LYL/nhubbsfc/3DNb9Aw5sg/gkmPRJv2E58qyDNy6BeijcBLtXhy5rYM8aqAsd7R6XCEOOhiNOh5mXwOCJPfxLiAE7V8Jbd/nh1mDAh/PcK2HsvPb/7mvL/f/HO3/yIZ6S43uPsy73PbtIcg6e/wm8sQgyh0PFPrh6OeRNiOzr9iIzW+Gcm9WpZSMZDJHQG8FQVFHLvJuf5r3UrxM3/iS/8QjUw3l3wpRu7FgVDMIz3/Ubxdlfg7N/6c8DEUteuAle+xV8/Ds+HNtTXwPvPeF/Vzve8hv7KefBrMtgzIlQst33DNb9A/a95/cKG38KHHMhTD4XUnMOr13BIBzYCrtX+c9717uw7d/gAjDmY3DcJf6zT0rvzrsf2AIN8P7T8Obv/WeWlOl/bydcAXnjO78e52D7G753vuEpCDbAEWfACV/3gd/TQ3+t/y9P+q6f+zj2i75HO0AoGLqpIRBk4o+e5c3BtzC8Yj0MmQpfuL9nvjmGfzM5dgF89g6Ij+SIXh/yxu/gX//tewDn/qbzPaa978GKe/1QQ20ZZAzzw0Tgj1SfdiFMPa/78xKtle+F1X+FlQ9A8YeQnOV7IcddAiOOi80eX1vqa3wv7807ofQjyB0Hc74JMy6GlKzurbt8D6y4z3/+5bv9PNS5t8PET/REy0M9+av8ENa8b8Mnfuo/16e/59/TNe9CTp/YWbLbFAw9YPqNS/nB+C18acQeOOX6nh3rdA5euw1evBmO/gxc8Ofm8daB6t2/+H/AKefBhfd07VtfXSWsexQ2PecnKKeeD7lje76trTkHH70JK++H9Y9DQ7X/snDcpTD9CwfvkRYJ9dWw4x3/TTohGSad6SdIoxlOgXo/5PfKL6Bspx8mOvEqP3zX09/qA/Xw/jPw4i1Q+L7/cvHJmyE5s+vrbKiFf3zV90pO/2846XvNv8/SAt9rOP4rcM6veuQtRJuCoQec8suXmD4qh98tmBm5F3nrLnjuB34s+5xfDajxzBY2PAWPXOr34FrwcP+e2K0p9cNXK+/3w03xSX7o6rhL/VBWTw0NNgbBttf9ZedyCNT5ITMX2q03a6QPiEmf9K/dW3vRBAP+d/DS//jht1Gz/W7bE06J/GvX1/jJ4Td+B9mjYf4dXXvduiq/t+CHL8BZt/r5j9aevMb3Ur+92h+b1M8pGHrA/Dv/TVZKAg98dU5kX2jlA/DPa/0/26Qz/d4YEz8xcOYetrzs91kfPgMufXxgjdHvWQfvPuA3HjUlfkM1dJrfiGSO8Huthd/uaFilrgoKGoPg3y2DYPgMGPdxGHeSP8tgfRV88Dx88C/48CWoK/cBNXYeHPkpHxSRmKx1zu899uItfnJ46DH+m/aRn+r9nstHb/u6ZMUf+v+ZM3/a+b+tmjJ46CLf+/rsIh/qbSneCr873u9iftbPeq7tUaJg6AEL732Hwopa/nn1SRF/Lcp2+/HMFfdCxV4/Rjvrq36PjN4YpoiUghVw32f8+7nsaX+8wkBUX+M3mOsf83tFle3yu2a2lpTh93jJCgVFZuhb6Edv+qKLwfq2g6CjQGmo8xO9m5b6sCh83z+ed0QoJM70gdGdocrGg9JevBl2rYRBk+C0H/phwWh+gamrghf/n+955471u8GO/VjHP1NVDH+5wO+Fdv5iP2fUkceu9J/rtWshI7/n2h4FCoYe8J2HV/HO1mL+/YPTI/5aTRrqYONTfne9j96AhBS/l83sr8OIGb3Xjp6wbyPce5Y/yO/ypZA5LNot6l311X6ytGx36Hqnv122s+XjOBgxszkIRs/p3oRt8VZ/fMimpb6oY0ONP1ZjyGS/6++gSb43MWiivz7Ut+ztb/qN7/Z/Q/YYOPV6v49/X9phYtu//a7gB7bD3P+AM37sD0BtrXwvPHAeFH0IX7gPjjr70Osu3Ax3zoaPXe13r+7HFAw94KdPreeRZTtYf9NZEX+tNu1Z5w/6WfOwHzoYNdsHxNTz+v5E9YHtvrCgc3D5c4e3q2IsCQb8pGpiSmTWX1flw+HDF2HfBr9BLCtouUzWyFBQTAqFxUS/9111iZ9D2Pw8ZAyFk//TD7n01b+92gr4vxv8/8ygiXDe3TB6dvPzJTt8xePy3bDgoY4rFrT296/C+8/Cd9b16x68gqEHLHrhA25/fhObbj6bpIQodperS2D1Q/4PvmgzpA32/6Czv+oruPY1Fft8KFQVwWXP+oMDpe+oq/Lj8kWb/aUwdF30gZ9YD5ea6483mf313j0CuTu2vAxPfMv3zD52DZz6X/72/fP93MLFf4MxhzlvuG8D/H6uD8fT/zsize4NCoYe8MCb2/jxE+t554dnMCQrQt/oDkcwCFtf9mW+Nz3nJxtP/p7/44/Ut7jyvb634oL+278LhvaICbsd/lywAf55nd/wXPoEjD4hMu2SnuecD/PGwKiv9qVKunscQjTUlMHzP/bzdvmT/RH0wQZf22z4sV1b58OX+NC5du3hHzzZRxxOMPShgcK+JSfN71J5oKq+bwRDXJzfrfWI0/1QzfM/8ZOBax6Bc26H8T04Sb5vgz9C+f1nutDORPjSwwqF/sYM0gf7y5i50W5N96RkwWd+648ReuJqP6G/8Bk/z9JVJ/8nbHgS3lkMp3y/59raRykY2pEbCoaSqroot6QNuWP95Nmmf/nzQdx3rj+K+pM3+3/srir5CF76mR+6Ss70B/blTQDM/3OZhS5x/kLY7cbH8ybA4B301EEAABIHSURBVEk99U5Fum7iJ+Calb630J0D4cAXVzzybHjr9/6Yh+6ur49TMLQjJ80XyTtQVR/llnTgyE/CuLf8UdT/XuQnyM68yRd+O5zdCCuLfP2iZX8EDD72Lfj4df16ok0EaHvvpK465T/9eViW/cnPvQxgA+Qoqp6Xm96HewzhktLgjJ/AN1/3E71PXeN3E927/tA/W1sBr/wSFs2At+/y5R2uWel7HgoFkZZGHu+L+b1xhy/PMoApGNqR2x96DOGGTIaFT/uDfAo/gLtPgn/9uO0/4IY6P4m9aCa8dLM/58GVb8L8O/vmnk4ifcUp34eqQj+xPYApGNqRmhhPUkJc3+8xhDODGV+Cq1f46zcWwZ1zYGNoEjkY9KWq75zt5yYGHwlf/T+46MHuTcyJxIoxc/2BiP9e5I94H6AUDO0wM3LTEjnQn4KhUVqeLy522XO+DMOSBfDXL8LiU3w1yaRMuPjvsPCfLQ8CEpFDO+X7vuz7uw9EuyURo2DoQG5aUv8ZSmrL2BPhm6/5GvNbXvEHMJ3/R/jGq76Gjs4nIHL4GkuXvP4bPyw7ACkYOpCTlti/hpLaEp8IH78Wrt8GV6/0E8wDpXKrSDSYwcnf9+VFVv812q2JCO2u2oHBGcm8uHEfd7z4ARfPGdu0p1K/FKl6PCKxaOIZvvjha7fDjC93vqhgfbUvcLju71C609cRyzvCH//TeEkfHPXevIKhA9edeSTlNQ3c9q9N3PHSZi48fhRf/fgExg8eQOcUEJHD19hrWLIA1v4NZixof9lAA2x9xe/4seEpf/6MjKEw5GjYucKX9W48+RL4U8jmjW8ZFnkTfIBkDOmV0FCtpE7YtLecP722hcff3UV9MMgnjh7K10+awOxxuZjG6UVik3N+t/CGarjqnZanM3XOn2Nj7d9g/aNQuR+Ss2HKZ+CYz/t5isblG+qgdAcUb/EVcIu3NF9KtvsjtxvNvQrO+p8uNVdF9CJkf3ktD7y5jQfe2s6Bqnqmj8rmaydN4NPThpEQr3F7kZiz/nH421f8eduPudDXGVv7N987KNkO8clw1Fk+DCaeefhDuoH65tAo3gpDpsC4eV1qqoIhwqrrAjz6bgF/fm0rWworGZmTymXzxvHF2aPJTEmMattE+ovK2gZSE+OJi+vHve5gEO460ZczT8mCvet8zbAJp/owmHxun6lQq2DoJcGg48WN+/jja1t4e2sxGckJXDR7NJ+YMpQj8jMYnJGkoaZ+qD4QZHtRJTX1QVKT4klPSiAtOZ60xHj1DLvIOceO4mqWbStm+fYDLN9WzAf7KkhLiufIoZlMHuYvRw3LYvKwzP61o8d7T8Ajl/qTaR3zeZj6OT8X0McoGKJgbUEpf3p9C/9cs5tA0P9Os1ISOGJIBkfkZzAxdH1Efjpj8tK0gekDahsCbCusYtPecj7YV8HmfeV8sLeCrYWVNATb/r9ISogjPSmetKQE0pLiSUtOIC0xnvTkeDJTEjn5yMF8auow0pJie7+OhkCQjXvKfRBsO8CybcXsK68FIDMlgVljc5kxOpcDVXW8v6ecjXvKWhwzNDQrmcmhkJg8PJOjhmZxxJB0khPi23vJLgsEHR8VV7Fxdxkb9pSzeV85I7JTmT0+j9nj8sjrTEjVVkByRo+3rScpGKKosKKWDbvL+HBfBZv3V/Dhvko+3F/R9E8BkBhvjB2UzhH56UwcksG4QenkpiWRmZJAZkoimSkJZKUmkpGcQHx/7ma3wTnH/opadh6opuBANTtLqkmIM4ZnpzIsO4Xh2SkMyUzuseAMBh0l1fXsLq1m874KPthbwQf7fBBsL6pqCvE4gzF5aUwamsmkIT7IM5ITqKoLhC4NVNYGqKpvoKo2QGVdA9V1ASrrAlTVNlBZF6Cwopb95bWkJcVz1tRhnH/cKE48YtCA+wxbc85RWl3Pe7vKWLbtAMu3F/PuRyVU1PpJ05E5qcwal8uscXnMHpfLkUMyDxo+cs6xr7yWjXvK2bi7jPf3lLNhTzkf7qugLuD32EmIM8YNTmdETirDs1IYnuP/XoZlp4auU8g6xFDugco6/xp7yti4u5yNe8vZtKec6voA4P8ORuelsbu0hroG/7qThmQwe3wec0JBMSKn+xVbK2r9309WakJEwq4tCoY+qKymng/3VfDhfh8U/rbfOLX37RQgIzkhFBgJZIVCIzMlkZTEOAJBCASDBFzoOujafCwYhIBzTd/CjhqWydHDshiVm9rj47vBoN/wFxyooiC08feXKnaWVLPzQDW1DcEO1xFnMCQzpSkomq/9BiA/I5mK2gaKK+s4UFVHUUXourKO4oo6iqvq/HOh58N/vfFxxthBaUwaksGRQzOZOCSDSUMymZCfTkpi9/5Bg0HH8u0HeOzdAv65ZjflNQ0MzUrmvBkjOf+4URw1rHdq+JfV1LO2oJTVBSWs2VHKhj1lJCfEkZ+ZzOAMf2m+nUR+ZjL5GcnkpScdFMjBoKOwspY9pTXsLq1hb5m/9ver2VNaw56yGmrq/WdqBpOHZTE7FASzxuZ2a0NaHwiytbCyKTA276tgT1kNu0pqKKyoPWj5jOSE5r+XrBSG56RS1xBsCoI9Zc31jXLTEjl6eJbvmQz3/xOThmaQkhhPbUOANQWlvLO1mGXbilmx7QDlYUE3Z3wes8fnccL4PCYMTm8xZFxTH2BPaQ27SqvZVVLD7pJqdoV+X7tL/OPlNc17GiUnxJGVmkhW6AthVkpi0/3MlESyUhOaHps8LJMjh3bt70jB0I/UB4LsPFBNWU09ZdUNlNfUU17TQFnouvl28/3ymnpq6oPEx1nLixlxcUZCnL+ON0iIiyMuDuLM2FlSzfaiqqbXTk+K58hhmUwelsXRwzM5aqi/nZ3W9rcu5xwHqurZVVLdtGHYFdpI7CqpbtpgNH7DazQoPYmRuamMyk1lVG4aI3Oab4/ISSEQdGEbmxr2hK13d6lfb1VdoMPfY5z5EiZ56UnkpicxKPw6LYkhWclMGpLJuMFpvfINraY+wAsb9vHoygJe2bSfhqBjyvAszj9uJJ+dMYIhmT1zwGFNfYD3dpexekcJa0JhsGV/c0XdcYPSmDoim/pAkMKKWgor6thfXtv0DTmcGeSlJTE4I5m05Hj2ldWyt6zmoC8uifHG0Cy/8W28HpadyoT8dI4fm3vIb+09pa4hyN4yH0xNfzclob+bMn9/X3ktCXHGxCGZHN04LDUsi6OHZZKfmdzpOcBA0LFhdxnLthU3hUVhha+KMDgjiaOHZ3Ggqo7dJTUUVR5cLSEvPYnh2SkMz05lRI6/TkuKb/H/XlbdeF1PWU1D6Lqe+kDz7//KU4/g+rO6VvCyzwSDmZ0F/BaIB/7knLu11fPJwP3A8UAR8EXn3LaO1jnQgqG3VdY2sGlvedM3MN+tLqe0unl8d3h2CpOHZTJ+cAYl1f6PvXED3frbfvhGYnh2KsNzUhiVm+Y3/DmpjMxN7fZ4u3OO8tqGpuDYX15LRnICgzJ8EOSlJZGdmthn924pqqjlqdW7ePTdnawpKCXO4KRJ+Zx/3EjOOHoo8WbUB4M0BBwNgSD1wdB1wNHQ+HjYYx8VV7K6oJTVO0p4f09504Z7SGYyx47O4dhR2UwflcP0UdlNp6htrbK2oWnoq7Cilv2hwCisqKWwvJbKugaGhnptwxq/fYeG+walJ/XZ33Vr9aEvKYk9PKfnnGNLYSXLthbzzrZiPthbwaCMJL/hz/Y9lcbr4dkpXe6NOueobQg2hURGciLDsrv2paJPBIOZxQObgDOBAmAZsMA5917YMv8BTHfOfdPMLgI+55z7YkfrVTD0POcce8tq2bDHj+02Bsb2oqqmbzrDslP82G52WAhkpzA4I7nfbCT6gs37Knjs3QIeW7mTXaVdL9uclZLA9FE5HDvah8Cxo3K6vMGQ2NBXguFE4Ebn3KdC9/8LwDn3s7BlloaWedPMEoA9QL7roFEKBhkIgkHH21uLWfnRAeJDw3+J8XEkxPvbCXH+dmJ8XKvn4hiWncLYvDQFshyWwwmGSO5TNxLYEXa/AJjT3jLOuQYzKwUGAYXhC5nZFcAVobsVZvZ+F9s0uPW6Y0wsv/9Yfu8Q2+9f790b29kf6hc7WzvnFgOLu7seM1ve2cQciGL5/cfye4fYfv9674f/3iN5lNVOYHTY/VGhx9pcJjSUlI2fhBYRkSiJZDAsAyaZ2XgzSwIuAp5stcyTwFdCty8EXuxofkFERCIvYkNJoTmDbwFL8bur3uOcW29mNwHLnXNPAn8GHjCzzUAxPjwiqdvDUf1cLL//WH7vENvvX+/9MPW7A9xERCSyVMlNRERaUDCIiEgLMRMMZnaWmb1vZpvN7AfRbk9vMrNtZrbWzFaZ2YA/OtDM7jGzfWa2LuyxPDN73sw+CF3nRrONkdLOe7/RzHaGPv9VZvbpaLYxUsxstJm9ZGbvmdl6M/t26PFY+ezbe/+H/fnHxBxDZ8pzDGRmtg2Y5ZyLiYN8zOxkoAK43zk3LfTYL4Bi59ytoS8Guc6566PZzkho573fCFQ4526LZtsizcyGA8OdcyvNLBNYAZwHLCQ2Pvv23v8XOMzPP1Z6DCcAm51zW5xzdcASYH6U2yQR4px7Fb+XW7j5wH2h2/fh/2EGnHbee0xwzu12zq0M3S4HNuCrK8TKZ9/e+z9ssRIMbZXn6NIvrJ9ywL/MbEWovEgsGuqc2x26vQcYGs3GRMG3zGxNaKhpQA6lhDOzccBM4G1i8LNv9f7hMD//WAmGWPdx59xxwNnAVaHhhpgVOohy4I+hNrsLOAKYAewGfhXd5kSWmWUA/wCudc6VhT8XC599G+//sD//WAmGzpTnGLCccztD1/uAx/BDa7Fmb2gMtnEsdl+U29NrnHN7nXMB51wQ+CMD+PM3s0T8RvFB59yjoYdj5rNv6/135fOPlWDoTHmOAcnM0kMTUZhZOvBJYF3HPzUghZdf+QrwRBTb0qsaN4ohn2OAfv7mT8f2Z2CDc+72sKdi4rNv7/135fOPib2SAEK7aP2G5vIct0S5Sb3CzCbgewngS6D8daC/dzN7CDgVX3J4L3AD8DjwCDAG2A58wTk34CZp23nvp+KHERywDfhG2Jj7gGFmHwdeA9YCjaca/CF+nD0WPvv23v8CDvPzj5lgEBGRzomVoSQREekkBYOIiLSgYBARkRYUDCIi0oKCQUREWlAwSL9mZoGwqpGrerJyrpmNC69S2sFyN5pZlZkNCXusojfbINKTInZqT5FeUu2cmxHtRgCFwHeBPlW108wSnHMN0W6H9C/qMciAFDoHxS9C56F4x8wmhh4fZ2YvhgqKvWBmY0KPDzWzx8xsdejysdCq4s3sj6H69v8ys9R2XvIe4ItmlteqHS2+8ZvZ90JlsDGzl83s12a23Mw2mNlsM3s0dN6Am8NWk2BmD4aW+buZpYV+/ngzeyVUHHFpWNmHl83sN+bPvfHt7v82JdYoGKS/S201lPTFsOdKnXPHAHfgj3oH+B1wn3NuOvAgsCj0+CLgFefcscBxwPrQ45OAO51zU4ES4IJ22lGBD4fD3RDXOedmAXfjSzVcBUwDFprZoNAyRwG/d84dDZQB/xGqifM74ELn3PGh1w4/oj3JOTfLOTegC+ZJZGgoSfq7joaSHgq7/nXo9onA+aHbDwC/CN0+HbgUwDkXAEpD5Ym3OudWhZZZAYzroC2LgFVmdjgnxGms2bUWWN9YqsDMtuALP5YAO5xz/w4t9xfgGuA5fIA870vkEI+vnNno4cNog0gLCgYZyFw7tw9HbdjtANDeUBLOuRIz+yv+W3+jBlr2zFPaWX+w1WsFaf7/bN12Bxg+SE5spzmV7bVT5FA0lCQD2RfDrt8M3X4DX10X4GJ80TGAF4ArwZ8K1syyu/iatwPfoHmjvhcYYmaDzCwZOLcL6xxjZo0B8CXgdeB9IL/xcTNLNLOpXWyzSAsKBunvWs8x3Br2XK6ZrcGP+38n9NjVwGWhxy+heU7g28BpZrYWP2Q0pSuNCZ1X+zEgOXS/HrgJeAd4HtjYhdW+jz/B0gYgF7grdIraC4Gfm9lqYBXwsQ7WIdJpqq4qA5KZbQNmhTbUInIY1GMQEZEW1GMQEZEW1GMQEZEWFAwiItKCgkFERFpQMIiISAsKBhERaeH/Ay70SEHDlIdbAAAAAElFTkSuQmCC\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "# 5. Analyze the loss curve\n",
        "\n",
        "history = np.array(history)\n",
        "plt.plot(history[:,0:2])\n",
        "plt.legend(['Tr Loss', 'Val Loss'])\n",
        "plt.xlabel('Epoch Number')\n",
        "plt.ylabel('Loss')\n",
        "plt.ylim(0,3)\n",
        "# plt.savefig('cifar10_loss_curve.png')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "PKGDjGqUMWET",
        "outputId": "1b20a875-ab03-4b61-f884-6f9e46a171e1"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "# 6. Analyze the accuracy curve\n",
        "\n",
        "plt.plot(history[:,2:4])\n",
        "plt.legend(['Tr Accuracy', 'Val Accuracy'])\n",
        "plt.xlabel('Epoch Number')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.ylim(0,1)\n",
        "# plt.savefig('cifar10_accuracy_curve.png')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lDnG9vWLMWEa"
      },
      "source": [
        "## Inference on webcam"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "XG_5s-GNMWEb"
      },
      "outputs": [],
      "source": [
        "# import dependencies\n",
        "from IPython.display import display, Javascript, Image\n",
        "from google.colab.output import eval_js\n",
        "from base64 import b64decode, b64encode\n",
        "import cv2\n",
        "import numpy as np\n",
        "import PIL\n",
        "import io\n",
        "import html\n",
        "import time\n",
        "\n",
        "\n",
        "# function to convert the JavaScript object into an OpenCV image\n",
        "def js_to_image(js_reply):\n",
        "  \"\"\"\n",
        "  Params:\n",
        "          js_reply: JavaScript object containing image from webcam\n",
        "  Returns:\n",
        "          img: OpenCV BGR image\n",
        "  \"\"\"\n",
        "  # decode base64 image\n",
        "  image_bytes = b64decode(js_reply.split(',')[1])\n",
        "  # convert bytes to numpy array\n",
        "  jpg_as_np = np.frombuffer(image_bytes, dtype=np.uint8)\n",
        "  # decode numpy array into OpenCV BGR image\n",
        "  img = cv2.imdecode(jpg_as_np, flags=1)\n",
        "\n",
        "  return img\n",
        "\n",
        "# function to convert OpenCV Rectangle bounding box image into base64 byte string to be overlayed on video stream\n",
        "def bbox_to_bytes(bbox_array):\n",
        "  \"\"\"\n",
        "  Params:\n",
        "          bbox_array: Numpy array (pixels) containing rectangle to overlay on video stream.\n",
        "  Returns:\n",
        "        bytes: Base64 image byte string\n",
        "  \"\"\"\n",
        "  # convert array into PIL image\n",
        "  bbox_PIL = PIL.Image.fromarray(bbox_array, 'RGBA')\n",
        "  iobuf = io.BytesIO()\n",
        "  # format bbox into png for return\n",
        "  bbox_PIL.save(iobuf, format='png')\n",
        "  # format return string\n",
        "  bbox_bytes = 'data:image/png;base64,{}'.format((str(b64encode(iobuf.getvalue()), 'utf-8')))\n",
        "\n",
        "  return bbox_bytes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "bwMGuVXVMWEb"
      },
      "outputs": [],
      "source": [
        "# JavaScript to properly create our live video stream using our webcam as input\n",
        "def video_stream():\n",
        "  js = Javascript('''\n",
        "    var video;\n",
        "    var div = null;\n",
        "    var stream;\n",
        "    var captureCanvas;\n",
        "    var imgElement;\n",
        "    var labelElement;\n",
        "    \n",
        "    var pendingResolve = null;\n",
        "    var shutdown = false;\n",
        "    \n",
        "    function removeDom() {\n",
        "       stream.getVideoTracks()[0].stop();\n",
        "       video.remove();\n",
        "       div.remove();\n",
        "       video = null;\n",
        "       div = null;\n",
        "       stream = null;\n",
        "       imgElement = null;\n",
        "       captureCanvas = null;\n",
        "       labelElement = null;\n",
        "    }\n",
        "    \n",
        "    function onAnimationFrame() {\n",
        "      if (!shutdown) {\n",
        "        window.requestAnimationFrame(onAnimationFrame);\n",
        "      }\n",
        "      if (pendingResolve) {\n",
        "        var result = \"\";\n",
        "        if (!shutdown) {\n",
        "          captureCanvas.getContext('2d').drawImage(video, 0, 0, 640, 480);\n",
        "          result = captureCanvas.toDataURL('image/jpeg', 0.8)\n",
        "        }\n",
        "        var lp = pendingResolve;\n",
        "        pendingResolve = null;\n",
        "        lp(result);\n",
        "      }\n",
        "    }\n",
        "    \n",
        "    async function createDom() {\n",
        "      if (div !== null) {\n",
        "        return stream;\n",
        "      }\n",
        "\n",
        "      div = document.createElement('div');\n",
        "      div.style.border = '2px solid black';\n",
        "      div.style.padding = '3px';\n",
        "      div.style.width = '100%';\n",
        "      div.style.maxWidth = '600px';\n",
        "      document.body.appendChild(div);\n",
        "      \n",
        "      const modelOut = document.createElement('div');\n",
        "      modelOut.innerHTML = \"<span>Status:</span>\";\n",
        "      labelElement = document.createElement('span');\n",
        "      labelElement.innerText = 'No data';\n",
        "      labelElement.style.fontWeight = 'bold';\n",
        "      modelOut.appendChild(labelElement);\n",
        "      div.appendChild(modelOut);\n",
        "           \n",
        "      video = document.createElement('video');\n",
        "      video.style.display = 'block';\n",
        "      video.width = div.clientWidth - 6;\n",
        "      video.setAttribute('playsinline', '');\n",
        "      video.onclick = () => { shutdown = true; };\n",
        "      stream = await navigator.mediaDevices.getUserMedia(\n",
        "          {video: { facingMode: \"environment\"}});\n",
        "      div.appendChild(video);\n",
        "\n",
        "      imgElement = document.createElement('img');\n",
        "      imgElement.style.position = 'absolute';\n",
        "      imgElement.style.zIndex = 1;\n",
        "      imgElement.onclick = () => { shutdown = true; };\n",
        "      div.appendChild(imgElement);\n",
        "      \n",
        "      const instruction = document.createElement('div');\n",
        "      instruction.innerHTML = \n",
        "          '<span style=\"color: red; font-weight: bold;\">' +\n",
        "          'When finished, click here or on the video to stop this demo</span>';\n",
        "      div.appendChild(instruction);\n",
        "      instruction.onclick = () => { shutdown = true; };\n",
        "      \n",
        "      video.srcObject = stream;\n",
        "      await video.play();\n",
        "\n",
        "      captureCanvas = document.createElement('canvas');\n",
        "      captureCanvas.width = 640; //video.videoWidth;\n",
        "      captureCanvas.height = 480; //video.videoHeight;\n",
        "      window.requestAnimationFrame(onAnimationFrame);\n",
        "      \n",
        "      return stream;\n",
        "    }\n",
        "    async function stream_frame(label, imgData) {\n",
        "      if (shutdown) {\n",
        "        removeDom();\n",
        "        shutdown = false;\n",
        "        return '';\n",
        "      }\n",
        "\n",
        "      var preCreate = Date.now();\n",
        "      stream = await createDom();\n",
        "      \n",
        "      var preShow = Date.now();\n",
        "      if (label != \"\") {\n",
        "        labelElement.innerHTML = label;\n",
        "      }\n",
        "            \n",
        "      if (imgData != \"\") {\n",
        "        var videoRect = video.getClientRects()[0];\n",
        "        imgElement.style.top = videoRect.top + \"px\";\n",
        "        imgElement.style.left = videoRect.left + \"px\";\n",
        "        imgElement.style.width = videoRect.width + \"px\";\n",
        "        imgElement.style.height = videoRect.height + \"px\";\n",
        "        imgElement.src = imgData;\n",
        "      }\n",
        "      \n",
        "      var preCapture = Date.now();\n",
        "      var result = await new Promise(function(resolve, reject) {\n",
        "        pendingResolve = resolve;\n",
        "      });\n",
        "      shutdown = false;\n",
        "      \n",
        "      return {'create': preShow - preCreate, \n",
        "              'show': preCapture - preShow, \n",
        "              'capture': Date.now() - preCapture,\n",
        "              'img': result};\n",
        "    }\n",
        "    ''')\n",
        "\n",
        "  display(js)\n",
        "  \n",
        "def video_frame(label, bbox):\n",
        "  data = eval_js('stream_frame(\"{}\", \"{}\")'.format(label, bbox))\n",
        "  return data"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "transform=transforms.Compose([\n",
        "    transforms.ToPILImage(),\n",
        "    transforms.Resize(256),\n",
        "    transforms.CenterCrop(size=224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.5, 0.5, 0.5],\n",
        "                         [0.5, 0.5, 0.5])\n",
        "    ])\n"
      ],
      "metadata": {
        "id": "OhU8PD4bQrPQ"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "categories = ['durian', 'pumpkin', 'tomato', 'watermelon']"
      ],
      "metadata": {
        "id": "_vXWH2YARFS-"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lx3Ny1u4MWEb"
      },
      "outputs": [],
      "source": [
        "\n",
        "from google.colab.patches import cv2_imshow\n",
        "# start streaming video from webcam\n",
        "video_stream()\n",
        "# label for video\n",
        "label_html = 'Capturing...'\n",
        "# initialze bounding box to empty\n",
        "bbox = ''\n",
        "count = 0 \n",
        "while True:\n",
        "    js_reply = video_frame(label_html, bbox)\n",
        "    if not js_reply:\n",
        "        break\n",
        "\n",
        "    # convert JS response to OpenCV Image\n",
        "    frame = js_to_image(js_reply[\"img\"])\n",
        "\n",
        "    #     rgb_image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "    # Apply transforms to the input image.\n",
        "    input_tensor = transform(frame)\n",
        "    # Add the batch dimension.\n",
        "    input_batch = input_tensor.unsqueeze(0)\n",
        "    input_batch = input_batch.to(device)\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        start_time = time.time()\n",
        "        output = model(input_batch)\n",
        "        end_time = time.time()\n",
        "    # Get the softmax probabilities.\n",
        "    probabilities = torch.nn.functional.softmax(output[0], dim=0)\n",
        "    # Check the top 5 categories that are predicted.\n",
        "    top5_prob, top5_catid = torch.topk(probabilities, 4)\n",
        "    \n",
        "    cv2.putText(frame, f\"{top5_prob[0].item()*100:.3f}%\", (15, (1)*30), \n",
        "                cv2.FONT_HERSHEY_SIMPLEX,\n",
        "                1, (0, 0, 255), 2, cv2.LINE_AA)\n",
        "    cv2.putText(frame, f\"{categories[top5_catid[0]]}\", (160, (1)*30), \n",
        "                cv2.FONT_HERSHEY_SIMPLEX,\n",
        "                1, (0, 0, 255), 2, cv2.LINE_AA)\n",
        "    print(categories[top5_catid[0]], top5_prob[0].item())\n",
        "    cv2_imshow(frame)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3.7 (pytorch_hasan)",
      "language": "python",
      "name": "torch"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.9"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "24467040af7844ce80d75b6f3bfff95a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5abe6efdfef54ce38e3be7935ecb70d8",
              "IPY_MODEL_abab27aceb004801a37f2fe90620c380",
              "IPY_MODEL_895143685ea34162acaee75e5cc58d7f"
            ],
            "layout": "IPY_MODEL_d5a7f46aedf5448fa8b03c205bd4786d"
          }
        },
        "5abe6efdfef54ce38e3be7935ecb70d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f6c8b86d7ceb4fd8a497570528bd01cd",
            "placeholder": "",
            "style": "IPY_MODEL_4867f348618f48a08f2ff5bdf9884c4c",
            "value": "100%"
          }
        },
        "abab27aceb004801a37f2fe90620c380": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ac0eb3da0e84414bb2901044f22eea4d",
            "max": 102530333,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5ff148ca407e43a9b3d509eba45b4009",
            "value": 102530333
          }
        },
        "895143685ea34162acaee75e5cc58d7f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9bea6abd53c04a3cac498da0b390c872",
            "placeholder": "",
            "style": "IPY_MODEL_8e541fff26824886a033eb49fc4eea40",
            "value": " 97.8M/97.8M [00:00&lt;00:00, 101MB/s]"
          }
        },
        "d5a7f46aedf5448fa8b03c205bd4786d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f6c8b86d7ceb4fd8a497570528bd01cd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4867f348618f48a08f2ff5bdf9884c4c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ac0eb3da0e84414bb2901044f22eea4d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5ff148ca407e43a9b3d509eba45b4009": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9bea6abd53c04a3cac498da0b390c872": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8e541fff26824886a033eb49fc4eea40": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}